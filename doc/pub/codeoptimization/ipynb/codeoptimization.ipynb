{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- dom:TITLE: Slides PHY 480 and PHY 905  Lectures: How to optimize codes, from vectorization to parallelization -->\n",
    "# Slides PHY 480 and PHY 905  Lectures: How to optimize codes, from vectorization to parallelization\n",
    "<!-- dom:AUTHOR: Phil Duxbury at Department of Physics and Astronomy, Michigan State University -->\n",
    "<!-- Author: --> **Phil Duxbury**, Department of Physics and Astronomy, Michigan State University\n",
    "\n",
    "<!-- dom:AUTHOR: Morten Hjorth-Jensen at Department of Physics, University of Oslo & Department of Physics and Astronomy and National Superconducting Cyclotron Laboratory, Michigan State University -->\n",
    "<!-- Author: --> **Morten Hjorth-Jensen**, Department of Physics, University of Oslo and Department of Physics and Astronomy and National Superconducting Cyclotron Laboratory, Michigan State University\n",
    "\n",
    "Date: **Spring 2016**\n",
    "\n",
    "## Content\n",
    "* Simple compiler options \n",
    "\n",
    "* Tools to benchmark your code\n",
    "\n",
    "* Machine architectures\n",
    "\n",
    "* What is vectorization?\n",
    "\n",
    "* Parallelization with OpenMP\n",
    "\n",
    "* Parallelization with MPI\n",
    "\n",
    "* Vectorization and parallelization, examples\n",
    "\n",
    "## Optimization and profiling\n",
    "\n",
    "\n",
    "Till now we have not paid much attention to speed and possible optimization possibilities\n",
    "inherent in the various compilers. We have compiled and linked as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        c++  -c  mycode.cpp\n",
    "        c++  -o  mycode.exe  mycode.o\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Fortran replace with for example **gfortran** or **ifort**.\n",
    "This is what we call a flat compiler option and should be used when we develop the code.\n",
    "It produces normally a very large and slow code when translated to machine instructions.\n",
    "We use this option for debugging and for establishing the correct program output because\n",
    "every operation is done precisely as the user specified it.\n",
    "\n",
    "It is instructive to look up the compiler manual for further instructions by writing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        man c++\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on optimization\n",
    "We have additional compiler options for optimization. These may include procedure inlining where \n",
    "performance may be improved, moving constants inside loops outside the loop, \n",
    "identify potential parallelism, include automatic vectorization or replace a division with a reciprocal\n",
    "and a multiplication if this speeds up the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        c++  -O3 -c  mycode.cpp\n",
    "        c++  -O3 -o  mycode.exe  mycode.o\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This (other options are -O2 or -Ofast) is the recommended option.\n",
    "\n",
    "\n",
    "## Optimization and profiling\n",
    "It is also useful to profile your program under the development stage.\n",
    "You would then compile with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        c++  -pg -O3 -c  mycode.cpp\n",
    "        c++  -pg -O3 -o  mycode.exe  mycode.o\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have run the code you can obtain the profiling information via"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        gprof mycode.exe >  ProfileOutput\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have profiled properly your code, you must take out this option as it \n",
    "slows down performance.\n",
    "For memory tests use [valgrind](http://www.valgrind.org). An excellent environment for all these aspects, and much  more, is  Qt creator.\n",
    "\n",
    "\n",
    "\n",
    "## Optimization and debugging\n",
    "Adding debugging options is a very useful alternative under the development stage of a program.\n",
    "You would then compile with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        c++  -g -O0 -c  mycode.cpp\n",
    "        c++  -g -O0 -o  mycode.exe  mycode.o\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This option generates debugging information allowing you to trace for example if an array is properly allocated. Some compilers work best with the no optimization option **-O0**.\n",
    "\n",
    "\n",
    "**Other optimization flags.**\n",
    "\n",
    "Depending on the compiler, one can add flags which generate code that catches integer overflow errors. \n",
    "The flag **-ftrapv** does this for the CLANG compiler on OS X operating systems.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Other hints\n",
    "In general, irrespective of compiler options, it is useful to\n",
    "* avoid if tests or call to functions inside loops, if possible. \n",
    "\n",
    "* avoid multiplication with constants inside loops if possible\n",
    "\n",
    "Here is an example of a part of a program where specific operations lead to a slower code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        k = n-1;\n",
    "        for (i = 0; i < n; i++){\n",
    "            a[i] = b[i] +c*d;\n",
    "            e = g[k];\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better code is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        temp = c*d;\n",
    "        for (i = 0; i < n; i++){\n",
    "            a[i] = b[i] + temp;\n",
    "        }\n",
    "        e = g[n-1];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we avoid a repeated multiplication inside a loop. \n",
    "Most compilers, depending on compiler flags, identify and optimize such bottlenecks on their own, without requiring any particular action by the programmer. However, it is always useful to single out and avoid code examples like the first one discussed here.\n",
    "\n",
    "\n",
    "\n",
    "## Vectorization and the basic idea behind parallel computing\n",
    "Present CPUs are highly parallel processors with varying levels of parallelism. The typical situation can be described via the following three statements.\n",
    "* Pursuit of shorter computation time and larger simulation size gives rise to parallel computing.\n",
    "\n",
    "* Multiple processors are involved to solve a global problem.\n",
    "\n",
    "* The essence is to divide the entire computation evenly among collaborative processors.  Divide and conquer.\n",
    "\n",
    "Before we proceed with a more detailed discussion of topics like vectorization and parallelization, we need to remind ourselves about some basic features of different hardware models.\n",
    "\n",
    "\n",
    "\n",
    "## A rough classification of hardware models\n",
    "\n",
    "* Conventional single-processor computers are named SISD (single-instruction-single-data) machines.\n",
    "\n",
    "* SIMD (single-instruction-multiple-data) machines incorporate the idea of parallel processing, using a large number of processing units to execute the same instruction on different data.\n",
    "\n",
    "* Modern parallel computers are so-called MIMD (multiple-instruction-multiple-data) machines and can execute different instruction streams in parallel on different data.\n",
    "\n",
    "\n",
    "## Shared memory and distributed memory\n",
    "One way of categorizing modern parallel computers is to look at the memory configuration.\n",
    "* In shared memory systems the CPUs share the same address space. Any CPU can access any data in the global memory.\n",
    "\n",
    "* In distributed memory systems each CPU has its own memory.\n",
    "\n",
    "The CPUs are connected by some network and may exchange messages.\n",
    "\n",
    "\n",
    "\n",
    "## Different parallel programming paradigms\n",
    "\n",
    "* **Task parallelism**:  the work of a global problem can be divided into a number of independent tasks, which rarely need to synchronize.  Monte Carlo simulations represent a typical situation. Integration is another. However this paradigm is of limited use.\n",
    "\n",
    "* **Data parallelism**:  use of multiple threads (e.g. one or more threads per processor) to dissect loops over arrays etc.  Communication and synchronization between processors are often hidden, thus easy to program. However, the user surrenders much control to a specialized compiler. Examples of data parallelism are compiler-based parallelization and OpenMP directives.\n",
    "\n",
    "\n",
    "## Different parallel programming paradigms\n",
    "\n",
    "* **Message passing**:  all involved processors have an independent memory address space. The user is responsible for  partitioning the data/work of a global problem and distributing the  subproblems to the processors. Collaboration between processors is achieved by explicit message passing, which is used for data transfer plus synchronization.\n",
    "\n",
    "* This paradigm is the most general one where the user has full control. Better parallel efficiency is usually achieved by explicit message passing. However, message-passing programming is more difficult.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!-- !split  -->\n",
    "## What is vectorization?\n",
    "Vectorization is a special\n",
    "case of **Single Instructions Multiple Data** (SIMD) to denote a single\n",
    "instruction stream capable of operating on multiple data elements in\n",
    "parallel. \n",
    "We can think of vectorization as the unrolling of loops accompanied with SIMD instructions.\n",
    "\n",
    "Vectorization is the process of converting an algorithm that performs scalar operations\n",
    "(typically one operation at the time) to vector operations where a single operation can refer to many simultaneous operations.\n",
    "Consider the following example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        for (i = 0; i < n; i++){\n",
    "            a[i] = b[i] + c[i];\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the code is not vectorized, the compiler will simply start with the first element and \n",
    "then perform subsequent additions operating on one address in memory at the time. \n",
    "\n",
    "<!-- !split  -->\n",
    "## Number of elements that can acted upon\n",
    "A SIMD instruction can operate  on multiple data elements in one single instruction.\n",
    "It uses the so-called 128-bit SIMD floating-point register. \n",
    "In this sense,vectorization adds some form of parallelism since one instruction is applied  \n",
    "to many parts of say a vector.\n",
    "\n",
    "The number of elements which can be operated on in parallel\n",
    "range from four single-precision floating point data elements in so-called \n",
    "Streaming SIMD Extensions and two double-precision floating-point data\n",
    "elements in Streaming SIMD Extensions 2 to sixteen byte operations in\n",
    "a 128-bit register in Streaming SIMD Extensions 2. Thus, vector-length\n",
    "ranges from 2 to 16, depending on the instruction extensions used and\n",
    "on the data type. \n",
    "\n",
    "<!-- !split  -->\n",
    "## Number of elements that can acted upon, examples\n",
    "We start with the simple scalar operations given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        for (i = 0; i < n; i++){\n",
    "            a[i] = b[i] + c[i];\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the code is not vectorized  and we have a 128-bit register to store a 32 bits floating point number,\n",
    "it means that we have $3\\times 32$ bits that are not used. For the first element we have\n",
    "\n",
    "\n",
    "<table border=\"1\">\n",
    "<thead>\n",
    "<tr><th align=\"center\">  0  </th> <th align=\"center\">   1    </th> <th align=\"center\">   2    </th> <th align=\"center\">   3    </th> </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td align=\"center\">   a[0]=    </td> <td align=\"center\">   not used    </td> <td align=\"center\">   not used    </td> <td align=\"center\">   not used    </td> </tr>\n",
    "<tr><td align=\"center\">   b[0]+    </td> <td align=\"center\">   not used    </td> <td align=\"center\">   not used    </td> <td align=\"center\">   not used    </td> </tr>\n",
    "<tr><td align=\"center\">   c[0]     </td> <td align=\"center\">   not used    </td> <td align=\"center\">   not used    </td> <td align=\"center\">   not used    </td> </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "We have thus unused space in our SIMD registers. These registers could hold three additional integers.\n",
    "\n",
    "\n",
    "\n",
    "<!-- !split  -->\n",
    "## Number of elements that can acted upon, examples\n",
    "If we vectorize the code, we can perform, with a 128-bit register four simultaneous operations, that is\n",
    "we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        for (i = 0; i < n; i+=4){\n",
    "            a[i] = b[i] + c[i];\n",
    "            a[i+1] = b[i+1] + c[i+1];\n",
    "            a[i+2] = b[i+2] + c[i+2];\n",
    "            a[i+3] = b[i+3] + c[i+3];\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "displayed here as\n",
    "\n",
    "<table border=\"1\">\n",
    "<thead>\n",
    "<tr><th align=\"center\">  0  </th> <th align=\"center\">  1  </th> <th align=\"center\">  2  </th> <th align=\"center\">  3  </th> </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td align=\"center\">   a[0]=    </td> <td align=\"center\">   a[1]=    </td> <td align=\"center\">   a[2]=    </td> <td align=\"center\">   a[3]=    </td> </tr>\n",
    "<tr><td align=\"center\">   b[0]+    </td> <td align=\"center\">   b[1]+    </td> <td align=\"center\">   b[2]+    </td> <td align=\"center\">   b[3]+    </td> </tr>\n",
    "<tr><td align=\"center\">   c[0]     </td> <td align=\"center\">   c[1]     </td> <td align=\"center\">   c[2]     </td> <td align=\"center\">   c[3]     </td> </tr>\n",
    "</tbody>\n",
    "</table>\n",
    "Four additions are now done in a single step.\n",
    "\n",
    "## [A simple test case with and without vectorization](https://github.com/CompPhysics/ComputationalPhysicsMSU/blob/master/doc/Programs/LecturePrograms/programs/Classes/cpp/program7.cpp)\n",
    "We implement these operations in a simple c++ program as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #include <cstdlib>\n",
    "        #include <iostream>\n",
    "        #include <cmath>\n",
    "        #include <iomanip>\n",
    "        #include \"time.h\" \n",
    "        \n",
    "        using namespace std; // note use of namespace                                       \n",
    "        int main (int argc, char* argv[])\n",
    "        {\n",
    "          int i = atoi(argv[1]); \n",
    "          double *a, *b, *c;\n",
    "          a = new double[i]; \n",
    "          b = new double[i]; \n",
    "          c = new double[i]; \n",
    "          for (int j = 0; j < i; j++) {\n",
    "            a[j] = 0.0;\n",
    "            b[j] = cos(j*1.0);\n",
    "            c[j] = sin(j*3.0);\n",
    "          }\n",
    "          clock_t start, finish;\n",
    "          start = clock();\n",
    "          for (int j = 0; j < i; j++) {\n",
    "            a[j] = b[j]+b[j]*c[j];\n",
    "          }\n",
    "          finish = clock();\n",
    "          double timeused = (double) (finish - start)/(CLOCKS_PER_SEC );\n",
    "          cout << setiosflags(ios::showpoint | ios::uppercase);\n",
    "          cout << setprecision(10) << setw(20) << \"Time used  for vector addition and multiplication=\" << timeused  << endl;\n",
    "          delete [] a;\n",
    "          delete [] b;\n",
    "          delete [] c;\n",
    "          return 0;     \n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- !split  -->\n",
    "## Compiling with and without vectorization\n",
    "We can compile and link without vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        c++ -o novec.x vecexample.cpp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and with vectorization (and additional optimizations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        c++ -O3 -o  vec.x vecexample.cpp \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The speedup depends on the size of the vectors. In the example here we have run with $10^7$ elements.\n",
    "The example here was run on a PC with ubuntu 14.04 as operating system and an Intel i7-4790 CPU running at 3.60 GHz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Compphys:~ hjensen$ ./vec.x 10000000\n",
    "        Time used  for vector addition = 0.0100000\n",
    "        Compphys:~ hjensen$ ./novec.x 10000000\n",
    "        Time used  for vector addition = 0.03000000000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular C++ compiler speeds up the above loop operations with a factor of 3. \n",
    "Performing the same operations for $10^8$ elements results only in a factor $1.4$.\n",
    "The result will however vary from compiler to compiler. In general however, with optimization flags like $-O3$ or $-Ofast$, we gain a considerable speedup if our code can be vectorized. Many of these operations can be done automatically by your compiler. These automatic or near automatic compiler techniques improve performance considerably. \n",
    "\n",
    "## Automatic vectorization and vectorization inhibitors, criteria\n",
    "\n",
    "Not all loops can be vectorized, as discussed in [Intel's guide to vectorization](https://software.intel.com/en-us/articles/a-guide-to-auto-vectorization-with-intel-c-compilers)\n",
    "\n",
    "An important criteria is that the loop counter $n$ is known at the entry of the loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "          for (int j = 0; j < n; j++) {\n",
    "            a[j] = cos(j*1.0);\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable $n$ does need to be known at compile time. However, this variable must stay the same for the entire duration of the loop. It implies that an exit statement inside the loop cannot be data dependent.\n",
    "\n",
    "## Automatic vectorization and vectorization inhibitors, exit criteria\n",
    "\n",
    "An exit statement should in general be avoided. \n",
    "If the exit statement contains data-dependent conditions, the loop cannot be vectorized. \n",
    "The following is an example of a non-vectorizable loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "          for (int j = 0; j < n; j++) {\n",
    "            a[j] = cos(j*1.0);\n",
    "            if (a[j] < 0 ) break;\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avoid loop termination conditions and opt for a single entry loop variable $n$. The lower and upper bounds have to be kept fixed within the loop. \n",
    "## Automatic vectorization and vectorization inhibitors, straight-line code\n",
    "SIMD instructions perform the same type of operations multiple times. \n",
    "A **switch** statement leads thus to a non-vectorizable loop since different statemens cannot branch.\n",
    "The following code can however be vectorized since the **if** statement is implemented as a masked assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "          for (int j = 0; j < n; j++) {\n",
    "            double x  = cos(j*1.0);\n",
    "            if (x > 0 ) {\n",
    "               a[j] =  x*sin(j*2.0); \n",
    "            }\n",
    "            else {\n",
    "               a[j] = 0.0;\n",
    "            }\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These operations can be performed for all data elements but only those elements which the mask evaluates as true are stored. In general, one should avoid branches such as **switch**, **go to**, or **return** statements or **if** constructs that cannot be treated as masked assignments. \n",
    "\n",
    "\n",
    "## Automatic vectorization and vectorization inhibitors, nested loops\n",
    "\n",
    "Only the innermost loop of the following example is vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "          for (int i = 0; i < n; i++) {\n",
    "              for (int j = 0; j < n; j++) {\n",
    "                   a[i][j] += b[i][j];\n",
    "              }  \n",
    "          }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exception is if an original outer loop is transformed into an inner loop as the result of compiler optimizations.\n",
    "\n",
    "\n",
    "## Automatic vectorization and vectorization inhibitors, function calls\n",
    "\n",
    "Calls to programmer defined functions ruin vectorization. However, calls to intrinsic functions like\n",
    "$\\sin{x}$, $\\cos{x}$, $\\exp{x}$ etc are allowed since they are normally efficiently vectorized. \n",
    "The following example is fully vectorizable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "          for (int i = 0; i < n; i++) {\n",
    "              a[i] = log10(i)*cos(i);\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, **inline** functions defined by the programmer, allow for vectorization since the function statements are glued into the actual place where the function is called. \n",
    "\n",
    "\n",
    "## Automatic vectorization and vectorization inhibitors, data dependencies\n",
    "\n",
    "One has to keep in mind that vectorization changes the order of operations inside a loop. A so-called\n",
    "read-after-write statement with an explicit flow dependency cannot be vectorized. The following code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "          double b = 15.;\n",
    "          for (int i = 1; i < n; i++) {\n",
    "              a[i] = a[i-1] + b;\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is an example of flow dependency and results in wrong numerical results if vectorized. For a scalar operation, the value $a[i-1]$ computed during the iteration is loaded into the right-hand side and the results are fine. In vector mode however, with a vector length of four, the values $a[0]$, $a[1]$, $a[2]$ and $a[3]$ from the previous loop will be loaded into the right-hand side and produce wrong results. That is, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "           a[1] = a[0] + b;\n",
    "           a[2] = a[1] + b;\n",
    "           a[3] = a[2] + b;\n",
    "           a[4] = a[3] + b;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and if the two first iterations are  executed at the same by the SIMD instruction, the value of say $a[1]$ could be used by the second iteration before it has been calculated by the first iteration, leading thereby to wrong results.\n",
    "\n",
    "## Automatic vectorization and vectorization inhibitors, more data dependencies\n",
    "\n",
    "On the other hand,  a so-called \n",
    "write-after-read statement can be vectorized. The following code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "          double b = 15.;\n",
    "          for (int i = 1; i < n; i++) {\n",
    "              a[i-1] = a[i] + b;\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is an example of flow dependency that can be vectorized since no iteration with a higher value of $i$\n",
    "can complete before an iteration with a lower value of $i$. However, such code leads to problems with parallelization.\n",
    "\n",
    "\n",
    "## Automatic vectorization and vectorization inhibitors, memory stride\n",
    "\n",
    "\n",
    "For C++ programmers  it is also worth keeping in mind that an array notation is preferred to the more compact use of pointers to access array elements. The compiler can often not tell if it is safe to vectorize the code. \n",
    "\n",
    "When dealing with arrays, you should also avoid memory stride, since this slows down considerably vectorization. When you access array element, write for example the inner loop to vectorize using unit stride, that is, access successively the next array element in memory, as shown here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "          for (int i = 0; i < n; i++) {\n",
    "              for (int j = 0; j < n; j++) {\n",
    "                   a[i][j] += b[i][j];\n",
    "              }  \n",
    "          }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today's situation of parallel computing\n",
    "\n",
    "* Distributed memory is the dominant hardware configuration. There is a large diversity in these machines, from  MPP (massively parallel processing) systems to clusters of off-the-shelf PCs, which are very cost-effective.\n",
    "\n",
    "* Message-passing is a mature programming paradigm and widely accepted. It often provides an efficient match to the hardware. It is primarily used for the distributed memory systems, but can also be used on shared memory systems.\n",
    "\n",
    "* Modern nodes have nowadays several cores, which makes it interesting to use both shared memory (the given node) and distributed memory (several nodes with communication). This leads often to codes which use both MPI and OpenMP.\n",
    "\n",
    "Our lectures will focus on both MPI and OpenMP.\n",
    "\n",
    "\n",
    "\n",
    "## Overhead present in parallel computing\n",
    "\n",
    "* **Uneven load balance**:  not all the processors can perform useful work at all time.\n",
    "\n",
    "* **Overhead of synchronization**\n",
    "\n",
    "* **Overhead of communication**\n",
    "\n",
    "* **Extra computation due to parallelization**\n",
    "\n",
    "Due to the above overhead and that certain parts of a sequential\n",
    "algorithm cannot be parallelized we may not achieve an optimal parallelization.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Parallelizing a sequential algorithm\n",
    "\n",
    "* Identify the part(s) of a sequential algorithm that can be  executed in parallel. This is the difficult part,\n",
    "\n",
    "* Distribute the global work and data among $P$ processors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Strategies\n",
    "* Develop codes locally, run with some few processes and test your codes.  Do benchmarking, timing and so forth on local nodes, for example your laptop or PC. \n",
    "\n",
    "* When you are convinced that your codes run correctly, you can start your production runs on available supercomputers.\n",
    "\n",
    "\n",
    "\n",
    "## How do I run MPI on a PC/Laptop?\n",
    "The  machines at the computer lab have eight CPUs (look up the file /proc/cpuinfo)\n",
    "* Compile with mpicxx or mpic++ or mpif90\n",
    "\n",
    "* Set up collaboration between processes and run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "          mpd --ncpus=8 &\n",
    "          #  run code with\n",
    "          mpiexec -n 8 ./nameofprog\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we declare that we will use 8 CPUs via the *-ncpus* option and via $-n 8$ when running.\n",
    "\n",
    "\n",
    "\n",
    "## Can I do it on my own PC/laptop?\n",
    "At the computer lab, we have installed both OpenMP and MPI. If you wish to install MPI and OpenMP \n",
    "on your laptop, we recommend the following:\n",
    "* For MPI, we recommend that you follow the instructions at the \"Open MPI\":\"www.open-mpi.org/software\" website and follow the instructions. OpenMPI is also accessible for easy installation for Ubuntu users via the **synaptic package manager**. \n",
    "\n",
    "* For OpenMP, the compile option **-fopenmp** is included automatically in recent versions of the C++ compiler and Fortran compilers. \n",
    "\n",
    "* For OS X users however, use for example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "          brew install clang-omp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Message Passing Interface (MPI)?\n",
    "\n",
    "**MPI** is a library, not a language. It specifies the names, calling sequences and results of functions\n",
    "or subroutines to be called from C/C++ or Fortran programs, and the classes and methods that make up the MPI C++\n",
    "library. The programs that users write in Fortran, C or C++ are compiled with ordinary compilers and linked\n",
    "with the MPI library.\n",
    "\n",
    "MPI programs should be able to run\n",
    "on all possible machines and run all MPI implementetations without change.\n",
    "\n",
    "An MPI computation is a collection of processes communicating with messages.\n",
    "\n",
    "\n",
    "## Going Parallel with MPI\n",
    "**Task parallelism**: the work of a global problem can be divided\n",
    "into a number of independent tasks, which rarely need to synchronize. \n",
    "Monte Carlo simulations or numerical integration are examples of this.\n",
    "\n",
    "\n",
    "MPI is a message-passing library where all the routines\n",
    "have corresponding C/C++-binding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "           MPI_Command_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and Fortran-binding (routine names are in uppercase, but can also be in lower case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "           MPI_COMMAND_NAME\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPI is a library\n",
    "MPI is a library specification for the message passing interface,\n",
    "proposed as a standard.\n",
    "\n",
    "* independent of hardware;\n",
    "\n",
    "* not a language or compiler specification;\n",
    "\n",
    "* not a specific implementation or product.\n",
    "\n",
    "A message passing standard for portability and ease-of-use. \n",
    "Designed for high performance.\n",
    "\n",
    "Insert communication and synchronization functions where necessary.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Bindings to MPI routines\n",
    "\n",
    "\n",
    "MPI is a message-passing library where all the routines\n",
    "have corresponding C/C++-binding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "           MPI_Command_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and Fortran-binding (routine names are in uppercase, but can also be in lower case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "           MPI_COMMAND_NAME\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discussion in these slides focuses on the C++ binding.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Communicator\n",
    "* A group of MPI processes with a name (context).\n",
    "\n",
    "* Any process is identified by its rank. The rank is only meaningful within a particular communicator.\n",
    "\n",
    "* By default the communicator contains all the MPI processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "          MPI_COMM_WORLD \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mechanism to identify subset of processes.\n",
    "\n",
    "* Promotes modular design of parallel libraries.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Some of the most  important MPI functions\n",
    "\n",
    "\n",
    "\n",
    "* $MPI\\_Init$ - initiate an MPI computation\n",
    "\n",
    "* $MPI\\_Finalize$ - terminate the MPI computation and clean up\n",
    "\n",
    "* $MPI\\_Comm\\_size$ - how many processes participate in a given MPI communicator?\n",
    "\n",
    "* $MPI\\_Comm\\_rank$ - which one am I? (A number between 0 and size-1.)\n",
    "\n",
    "* $MPI\\_Send$ - send a message to a particular process within an MPI communicator\n",
    "\n",
    "* $MPI\\_Recv$ - receive a message from a particular process within an MPI communicator\n",
    "\n",
    "* $MPI\\_reduce$  or $MPI\\_Allreduce$, send and receive messages\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## The first MPI C/C++ program\n",
    "\n",
    "\n",
    "Let every process write \"Hello world\" (oh not this program again!!) on the standard output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        using namespace std;\n",
    "        #include <mpi.h>\n",
    "        #include <iostream>\n",
    "        int main (int nargs, char* args[])\n",
    "        {\n",
    "        int numprocs, my_rank;\n",
    "        //   MPI initializations\n",
    "        MPI_Init (&nargs, &args);\n",
    "        MPI_Comm_size (MPI_COMM_WORLD, &numprocs);\n",
    "        MPI_Comm_rank (MPI_COMM_WORLD, &my_rank);\n",
    "        cout << \"Hello world, I have  rank \" << my_rank << \" out of \" \n",
    "             << numprocs << endl;\n",
    "        //  End MPI\n",
    "        MPI_Finalize ();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Fortran program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        PROGRAM hello\n",
    "        INCLUDE \"mpif.h\"\n",
    "        INTEGER:: size, my_rank, ierr\n",
    "        \n",
    "        CALL  MPI_INIT(ierr)\n",
    "        CALL MPI_COMM_SIZE(MPI_COMM_WORLD, size, ierr)\n",
    "        CALL MPI_COMM_RANK(MPI_COMM_WORLD, my_rank, ierr)\n",
    "        WRITE(*,*)\"Hello world, I've rank \",my_rank,\" out of \",size\n",
    "        CALL MPI_FINALIZE(ierr)\n",
    "        \n",
    "        END PROGRAM hello\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note 1\n",
    "\n",
    "* The output to screen is not ordered since all processes are trying to write  to screen simultaneously.\n",
    "\n",
    "* It is the operating system which opts for an ordering.  \n",
    "\n",
    "* If we wish to have an organized output, starting from the first process, we may rewrite our program as in the next example.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Ordered output with $MPI\\_Barrier$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        int main (int nargs, char* args[])\n",
    "        {\n",
    "         int numprocs, my_rank, i;\n",
    "         MPI_Init (&nargs, &args);\n",
    "         MPI_Comm_size (MPI_COMM_WORLD, &numprocs);\n",
    "         MPI_Comm_rank (MPI_COMM_WORLD, &my_rank);\n",
    "         for (i = 0; i < numprocs; i++) {}\n",
    "         MPI_Barrier (MPI_COMM_WORLD);\n",
    "         if (i == my_rank) {\n",
    "         cout << \"Hello world, I have  rank \" << my_rank << \n",
    "                \" out of \" << numprocs << endl;}\n",
    "              MPI_Finalize ();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note 2\n",
    "* Here we have used the $MPI\\_Barrier$ function to ensure that that every process has completed  its set of instructions in  a particular order.\n",
    "\n",
    "* A barrier is a special collective operation that does not allow the processes to continue until all processes in the communicator (here $MPI\\_COMM\\_WORLD$) have called $MPI\\_Barrier$. \n",
    "\n",
    "* The barriers make sure that all processes have reached the same point in the code. Many of the collective operations like $MPI\\_ALLREDUCE$ to be discussed later, have the same property; that is, no process can exit the operation until all processes have started. \n",
    "\n",
    "However, this is slightly more time-consuming since the processes synchronize between themselves as many times as there\n",
    "are processes.  In the next Hello world example we use the send and receive functions in order to a have a synchronized\n",
    "action.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Ordered output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        .....\n",
    "        int numprocs, my_rank, flag;\n",
    "        MPI_Status status;\n",
    "        MPI_Init (&nargs, &args);\n",
    "        MPI_Comm_size (MPI_COMM_WORLD, &numprocs);\n",
    "        MPI_Comm_rank (MPI_COMM_WORLD, &my_rank);\n",
    "        if (my_rank > 0)\n",
    "        MPI_Recv (&flag, 1, MPI_INT, my_rank-1, 100, \n",
    "                   MPI_COMM_WORLD, &status);\n",
    "        cout << \"Hello world, I have  rank \" << my_rank << \" out of \" \n",
    "        << numprocs << endl;\n",
    "        if (my_rank < numprocs-1)\n",
    "        MPI_Send (&my_rank, 1, MPI_INT, my_rank+1, \n",
    "                  100, MPI_COMM_WORLD);\n",
    "        MPI_Finalize ();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note 3\n",
    "\n",
    "\n",
    "The basic sending of messages is given by the function $MPI\\_SEND$, which in C/C++\n",
    "is defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        int MPI_Send(void *buf, int count, \n",
    "                     MPI_Datatype datatype, \n",
    "                     int dest, int tag, MPI_Comm comm)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This single command allows the passing of any kind of variable, even a large array, to any group of tasks. \n",
    "The variable **buf** is the variable we wish to send while **count**\n",
    "is the  number of variables we are passing. If we are passing only a single value, this should be 1. \n",
    "\n",
    "If we transfer an array, it is  the overall size of the array. \n",
    "For example, if we want to send a 10 by 10 array, count would be $10\\times 10=100$ \n",
    "since we are  actually passing 100 values.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Note 4\n",
    "\n",
    "Once you have  sent a message, you must receive it on another task. The function $MPI\\_RECV$\n",
    "is similar to the send call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        int MPI_Recv( void *buf, int count, MPI_Datatype datatype, \n",
    "                    int source, \n",
    "                    int tag, MPI_Comm comm, MPI_Status *status )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arguments that are different from those in MPI\\_SEND are\n",
    "**buf** which  is the name of the variable where you will  be storing the received data, \n",
    "**source** which  replaces the destination in the send command. This is the return ID of the sender.\n",
    "\n",
    "Finally,  we have used  $MPI\\_Status\\_status$,  \n",
    "where one can check if the receive was completed.\n",
    "\n",
    "The output of this code is the same as the previous example, but now\n",
    "process 0 sends a message to process 1, which forwards it further\n",
    "to process 2, and so forth.\n",
    "\n",
    "\n",
    "\n",
    "## Numerical integration in parallel\n",
    "**Integrating $\\pi$.**\n",
    "\n",
    "\n",
    "* The code example computes $\\pi$ using the trapezoidal rules.\n",
    "\n",
    "* The trapezoidal rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "I=\\int_a^bf(x) dx\\approx h\\left(f(a)/2 + f(a+h) +f(a+2h)+\\dots +f(b-h)+ f(b)/2\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissection of trapezoidal rule with $MPI\\_reduce$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        //    Trapezoidal rule and numerical integration usign MPI\n",
    "        using namespace std;\n",
    "        #include <mpi.h>\n",
    "        #include <iostream>\n",
    "        \n",
    "        //     Here we define various functions called by the main program\n",
    "        \n",
    "        double int_function(double );\n",
    "        double trapezoidal_rule(double , double , int , double (*)(double));\n",
    "        \n",
    "        //   Main function begins here\n",
    "        int main (int nargs, char* args[])\n",
    "        {\n",
    "          int n, local_n, numprocs, my_rank; \n",
    "          double a, b, h, local_a, local_b, total_sum, local_sum;   \n",
    "          double  time_start, time_end, total_time;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissection of trapezoidal rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "          //  MPI initializations\n",
    "          MPI_Init (&nargs, &args);\n",
    "          MPI_Comm_size (MPI_COMM_WORLD, &numprocs);\n",
    "          MPI_Comm_rank (MPI_COMM_WORLD, &my_rank);\n",
    "          time_start = MPI_Wtime();\n",
    "          //  Fixed values for a, b and n \n",
    "          a = 0.0 ; b = 1.0;  n = 1000;\n",
    "          h = (b-a)/n;    // h is the same for all processes \n",
    "          local_n = n/numprocs;  \n",
    "          // make sure n > numprocs, else integer division gives zero\n",
    "          // Length of each process' interval of\n",
    "          // integration = local_n*h.  \n",
    "          local_a = a + my_rank*local_n*h;\n",
    "          local_b = local_a + local_n*h;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating with **MPI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "          total_sum = 0.0;\n",
    "          local_sum = trapezoidal_rule(local_a, local_b, local_n, \n",
    "                                       &int_function); \n",
    "          MPI_Reduce(&local_sum, &total_sum, 1, MPI_DOUBLE, \n",
    "                      MPI_SUM, 0, MPI_COMM_WORLD);\n",
    "          time_end = MPI_Wtime();\n",
    "          total_time = time_end-time_start;\n",
    "          if ( my_rank == 0) {\n",
    "            cout << \"Trapezoidal rule = \" <<  total_sum << endl;\n",
    "            cout << \"Time = \" <<  total_time  \n",
    "                 << \" on number of processors: \"  << numprocs  << endl;\n",
    "          }\n",
    "          // End MPI\n",
    "          MPI_Finalize ();  \n",
    "          return 0;\n",
    "        }  // end of main program\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I use $MPI\\_reduce$?\n",
    "\n",
    "Here we have used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        MPI_reduce( void *senddata, void* resultdata, int count, \n",
    "             MPI_Datatype datatype, MPI_Op, int root, MPI_Comm comm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two variables $senddata$ and $resultdata$ are obvious, besides the fact that one sends the address\n",
    "of the variable or the first element of an array.  If they are arrays they need to have the same size. \n",
    "The variable $count$ represents the total dimensionality, 1 in case of just one variable, \n",
    "while $MPI\\_Datatype$ \n",
    "defines the type of variable which is sent and received.  \n",
    "\n",
    "The new feature is $MPI\\_Op$. It defines the type\n",
    "of operation we want to do.\n",
    "\n",
    "\n",
    "\n",
    "## More on $MPI\\_Reduce$\n",
    "In our case, since we are summing\n",
    "the rectangle  contributions from every process we define  $MPI\\_Op = MPI\\_SUM$.\n",
    "If we have an array or matrix we can search for the largest og smallest element by sending either $MPI\\_MAX$ or \n",
    "$MPI\\_MIN$.  If we want the location as well (which array element) we simply transfer \n",
    "$MPI\\_MAXLOC$ or $MPI\\_MINOC$. If we want the product we write $MPI\\_PROD$. \n",
    "\n",
    "$MPI\\_Allreduce$ is defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        MPI_Allreduce( void *senddata, void* resultdata, int count, \n",
    "                  MPI_Datatype datatype, MPI_Op, MPI_Comm comm)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissection of trapezoidal rule\n",
    "\n",
    "We use $MPI\\_reduce$ to collect data from each process. Note also the use of the function \n",
    "$MPI\\_Wtime$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        //  this function defines the function to integrate\n",
    "        double int_function(double x)\n",
    "        {\n",
    "          double value = 4./(1.+x*x);\n",
    "          return value;\n",
    "        } // end of function to evaluate\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dissection of trapezoidal rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        //  this function defines the trapezoidal rule\n",
    "        double trapezoidal_rule(double a, double b, int n, \n",
    "                                 double (*func)(double))\n",
    "        {\n",
    "          double trapez_sum;\n",
    "          double fa, fb, x, step;\n",
    "          int    j;\n",
    "          step=(b-a)/((double) n);\n",
    "          fa=(*func)(a)/2. ;\n",
    "          fb=(*func)(b)/2. ;\n",
    "          trapez_sum=0.;\n",
    "          for (j=1; j <= n-1; j++){\n",
    "            x=j*step+a;\n",
    "            trapez_sum+=(*func)(x);\n",
    "          }\n",
    "          trapez_sum=(trapez_sum+fb+fa)*step;\n",
    "          return trapez_sum;\n",
    "        }  // end trapezoidal_rule \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is OpenMP\n",
    "* OpenMP provides high-level thread programming\n",
    "\n",
    "* Multiple cooperating threads are allowed to run simultaneously\n",
    "\n",
    "* Threads are created and destroyed dynamically in a fork-join pattern\n",
    "\n",
    "   * An OpenMP program consists of a number of parallel regions\n",
    "\n",
    "   * Between two parallel regions there is only one master thread\n",
    "\n",
    "   * In the beginning of a parallel region, a team of new threads is spawned\n",
    "\n",
    "\n",
    "  * The newly spawned threads work simultaneously with the master thread\n",
    "\n",
    "  * At the end of a parallel region, the new threads are destroyed\n",
    "\n",
    "\n",
    "\n",
    "## Getting started, things to remember\n",
    " * Remember the header file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #include <omp.h>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Insert compiler directives in C++ syntax as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compile with for example *c++ -fopenmp code.cpp*\n",
    "\n",
    "* Execute\n",
    "\n",
    "  * Remember to assign the environment variable **OMP NUM THREADS**\n",
    "\n",
    "  * It specifies the total number of threads inside a parallel region, if not otherwise overwritten\n",
    "\n",
    "\n",
    "\n",
    "## General code structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #include <omp.h>\n",
    "        main ()\n",
    "        {\n",
    "        int var1, var2, var3;\n",
    "        /* serial code */\n",
    "        /* ... */\n",
    "        /* start of a parallel region */\n",
    "        #pragma omp parallel private(var1, var2) shared(var3)\n",
    "        {\n",
    "        /* ... */\n",
    "        }\n",
    "        /* more serial code */\n",
    "        /* ... */\n",
    "        /* another parallel region */\n",
    "        #pragma omp parallel\n",
    "        {\n",
    "        /* ... */\n",
    "        }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel region\n",
    "* A parallel region is a block of code that is executed by a team of threads\n",
    "\n",
    "* The following compiler directive creates a parallel region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp parallel { ... }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Clauses can be added at the end of the directive\n",
    "\n",
    "* Most often used clauses:\n",
    "\n",
    " * **default(shared)** or **default(none)**\n",
    "\n",
    " * **public(list of variables)**\n",
    "\n",
    " * **private(list of variables)**\n",
    "\n",
    "\n",
    "\n",
    "## Hello world, not again, please!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #include <omp.h>\n",
    "        #include <stdio.h>\n",
    "        int main (int argc, char *argv[])\n",
    "        {\n",
    "        int th_id, nthreads;\n",
    "        #pragma omp parallel private(th_id) shared(nthreads)\n",
    "        {\n",
    "        th_id = omp_get_thread_num();\n",
    "        printf(\"Hello World from thread %d\\n\", th_id);\n",
    "        #pragma omp barrier\n",
    "        if ( th_id == 0 ) {\n",
    "        nthreads = omp_get_num_threads();\n",
    "        printf(\"There are %d threads\\n\",nthreads);\n",
    "        }\n",
    "        }\n",
    "        return 0;\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important OpenMP library routines\n",
    "\n",
    "* **int omp get num threads ()**, returns the number of threads inside a parallel region\n",
    "\n",
    "* **int omp get thread num ()**,  returns the  a thread for each thread inside a parallel region\n",
    "\n",
    "* **void omp set num threads (int)**, sets the number of threads to be used\n",
    "\n",
    "* **void omp set nested (int)**,  turns nested parallelism on/off\n",
    "\n",
    "\n",
    "\n",
    "## Parallel for loop\n",
    " * Inside a parallel region, the following compiler directive can be used to parallelize a for-loop:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp for\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Clauses can be added, such as\n",
    "\n",
    "  * **schedule(static, chunk size)**\n",
    "\n",
    "  * **schedule(dynamic, chunk size)** \n",
    "\n",
    "  * **schedule(guided, chunk size)** (non-deterministic allocation)\n",
    "\n",
    "  * **schedule(runtime)**\n",
    "\n",
    "  * **private(list of variables)**\n",
    "\n",
    "  * **reduction(operator:variable)**\n",
    "\n",
    "  * **nowait**\n",
    "\n",
    "\n",
    "\n",
    "## Example code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #include <omp.h>\n",
    "        #define CHUNKSIZE 100\n",
    "        #define N\n",
    "        1000\n",
    "        main ()\n",
    "        {\n",
    "        int i, chunk;\n",
    "        float a[N], b[N], c[N];\n",
    "        for (i=0; i < N; i++)\n",
    "        a[i] = b[i] = i * 1.0;\n",
    "        chunk = CHUNKSIZE;\n",
    "        #pragma omp parallel shared(a,b,c,chunk) private(i)\n",
    "        {\n",
    "        #pragma omp for schedule(dynamic,chunk)\n",
    "        for (i=0; i < N; i++)\n",
    "        c[i] = a[i] + b[i];\n",
    "        } /* end of parallel region */\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on Parallel for loop\n",
    "* The number of loop iterations cannot be non-deterministic; break, return, exit, goto not allowed inside the for-loop\n",
    "\n",
    "* The loop index is private to each thread\n",
    "\n",
    "* A reduction variable is special\n",
    "\n",
    "  * During the for-loop there is a local private copy in each thread\n",
    "\n",
    "  * At the end of the for-loop, all the local copies are combined together by the reduction operation\n",
    "\n",
    "\n",
    "* Unless the nowait clause is used, an implicit barrier synchronization will be added at the end by the compiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        // #pragma omp parallel and #pragma omp for\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can be combined into"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp parallel for\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\n",
    " \n",
    "<\n",
    "<\n",
    "<\n",
    "!\n",
    "!\n",
    "M\n",
    "A\n",
    "T\n",
    "H\n",
    "_\n",
    "B\n",
    "L\n",
    "O\n",
    "C\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        int i;\n",
    "        double sum = 0.;\n",
    "        /* allocating and initializing arrays */\n",
    "        /* ... */\n",
    "        #pragma omp parallel for default(shared) private(i) reduction(+:sum)\n",
    "        for (i=0; i<N; i++)\n",
    "        sum += a[i]*b[i];\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different threads do different tasks\n",
    "\n",
    "Different threads do different tasks independently, each section is executed by one thread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp parallel\n",
    "        {\n",
    "        #pragma omp sections\n",
    "        {\n",
    "        #pragma omp section\n",
    "        funcA ();\n",
    "        #pragma omp section\n",
    "        funcB ();\n",
    "        #pragma omp section\n",
    "        funcC ();\n",
    "        }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp single { ... }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code is executed by one thread only, no guarantee which thread\n",
    "\n",
    "Can introduce an implicit barrier at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp master { ... }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code executed by the master thread, guaranteed and no implicit barrier at the end.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Coordination and synchronization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp barrier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synchronization, must be encountered by all threads in a team (or none)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp ordered { a block of codes }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is another form of synchronization (in sequential order).\n",
    "The form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp critical { a block of codes }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp atomic { single assignment statement }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is  more efficient than"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp critical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data scope\n",
    "* OpenMP data scope attribute clauses:\n",
    "\n",
    " * **shared**\n",
    "\n",
    " * **private**\n",
    "\n",
    " * **firstprivate**\n",
    "\n",
    " * **lastprivate**\n",
    "\n",
    " * **reduction**\n",
    "\n",
    "\n",
    "What are the purposes of these attributes\n",
    "* define how and which variables are transferred to a parallel region (and back)\n",
    "\n",
    "* define which variables are visible to all threads in a parallel region, and which variables are privately allocated to each thread\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Some remarks\n",
    "\n",
    "* When entering a parallel region, the **private** clause ensures each thread having its own new variable instances. The new variables are assumed to be uninitialized.\n",
    "\n",
    "* A shared variable exists in only one memory location and all threads can read and write to that address. It is the programmer's responsibility to ensure that multiple threads properly access a shared variable.\n",
    "\n",
    "* The **firstprivate** clause combines the behavior of the private clause with automatic initialization.\n",
    "\n",
    "* The **lastprivate** clause combines the behavior of the private clause with a copy back (from the last loop iteration or section) to the original variable outside the parallel region.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Parallelizing nested for-loops\n",
    "\n",
    " * Serial code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        for (i=0; i<100; i++)\n",
    "        for (j=0; j<100; j++)\n",
    "        a[i][j] = b[i][j] + c[i][j]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parallelization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp parallel for private(j)\n",
    "        for (i=0; i<100; i++)\n",
    "        for (j=0; j<100; j++)\n",
    "        a[i][j] = b[i][j] + c[i][j]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Why not parallelize the inner loop? to save overhead of repeated thread forks-joins\n",
    "\n",
    "* Why must **j** be private? To avoid race condition among the threads\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Nested parallelism\n",
    "When a thread in a parallel region encounters another parallel construct, it\n",
    "may create a new team of threads and become the master of the new\n",
    "team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp parallel num_threads(4)\n",
    "        {\n",
    "        /* .... */\n",
    "        #pragma omp parallel num_threads(2)\n",
    "        {\n",
    "        //  \n",
    "        }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp task \n",
    "        #pragma omp parallel shared(p_vec) private(i)\n",
    "        {\n",
    "        #pragma omp single\n",
    "        {\n",
    "        for (i=0; i<N; i++) {\n",
    "        double r = random_number();\n",
    "        if (p_vec[i] > r) {\n",
    "        #pragma omp task\n",
    "        do_work (p_vec[i]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common mistakes\n",
    "Race condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        int nthreads;\n",
    "        #pragma omp parallel shared(nthreads)\n",
    "        {\n",
    "        nthreads = omp_get_num_threads();\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deadlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        #pragma omp parallel\n",
    "        {\n",
    "        ...\n",
    "        #pragma omp critical\n",
    "        {\n",
    "        ...\n",
    "        #pragma omp barrier\n",
    "        }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix-matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        # include <cstdlib>\n",
    "        # include <iostream>\n",
    "        # include <cmath>\n",
    "        # include <ctime>\n",
    "        # include <omp.h>\n",
    "        \n",
    "        using namespace std;\n",
    "        \n",
    "        // Main function\n",
    "        int main ( )\n",
    "        {\n",
    "        // brute force coding of arrays\n",
    "          double a[500][500];\n",
    "          double angle;\n",
    "          double b[500][500];\n",
    "          double c[500][500];\n",
    "          int i;\n",
    "          int j;\n",
    "          int k;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix-matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "          int n = 500;\n",
    "          double pi = acos(-1.0);\n",
    "          double s;\n",
    "          int thread_num;\n",
    "          double wtime;\n",
    "        \n",
    "          cout << \"\\n\";\n",
    "          cout << \"  C++/OpenMP version\\n\";\n",
    "          cout << \"  Compute matrix product C = A * B.\\n\";\n",
    "        \n",
    "          thread_num = omp_get_max_threads ( );\n",
    "        \n",
    "        //\n",
    "        //  Loop 1: Evaluate A.\n",
    "        //\n",
    "          s = 1.0 / sqrt ( ( double ) ( n ) );\n",
    "        \n",
    "          wtime = omp_get_wtime ( );\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix-matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        # pragma omp parallel shared ( a, b, c, n, pi, s ) \n",
    "        private ( angle, i, j, k )\n",
    "        {\n",
    "          # pragma omp for\n",
    "          for ( i = 0; i < n; i++ )\n",
    "          {\n",
    "            for ( j = 0; j < n; j++ )\n",
    "            {\n",
    "              angle = 2.0 * pi * i * j / ( double ) n;\n",
    "              a[i][j] = s * ( sin ( angle ) + cos ( angle ) );\n",
    "            }\n",
    "          }\n",
    "        //\n",
    "        //  Loop 2: Copy A into B.\n",
    "        //\n",
    "          # pragma omp for\n",
    "          for ( i = 0; i < n; i++ )\n",
    "          {\n",
    "            for ( j = 0; j < n; j++ )\n",
    "            {\n",
    "              b[i][j] = a[i][j];\n",
    "            }\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix-matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        //  Loop 3: Compute C = A * B.\n",
    "        //\n",
    "          # pragma omp for\n",
    "          for ( i = 0; i < n; i++ )\n",
    "          {\n",
    "            for ( j = 0; j < n; j++ )\n",
    "            {\n",
    "              c[i][j] = 0.0;\n",
    "              for ( k = 0; k < n; k++ )\n",
    "              {\n",
    "                c[i][j] = c[i][j] + a[i][k] * b[k][j];\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "          wtime = omp_get_wtime ( ) - wtime;\n",
    "          cout << \"  Elapsed seconds = \" << wtime << \"\\n\";\n",
    "          cout << \"  C(100,100)  = \" << c[99][99] << \"\\n\";\n",
    "        //\n",
    "        //  Terminate.\n",
    "        //\n",
    "          cout << \"\\n\";\n",
    "          cout << \"  Normal end of execution.\\n\";\n",
    "          return 0;\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
